{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10050915,"sourceType":"datasetVersion","datasetId":6032820}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Bắt đầu code**","metadata":{}},{"cell_type":"code","source":"### Import các thư viện cần thiết\nimport torch\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    RobertaForSequenceClassification,\n    BertForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    AutoConfig,\n    EvalPrediction\n)\nfrom huggingface_hub import HfFolder, login\nfrom sklearn.metrics import classification_report\nimport pandas as pd\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:10:55.388943Z","iopub.execute_input":"2024-12-19T19:10:55.389508Z","iopub.status.idle":"2024-12-19T19:11:23.630342Z","shell.execute_reply.started":"2024-12-19T19:10:55.389471Z","shell.execute_reply":"2024-12-19T19:11:23.629343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:23.632026Z","iopub.execute_input":"2024-12-19T19:11:23.632609Z","iopub.status.idle":"2024-12-19T19:11:23.698760Z","shell.execute_reply.started":"2024-12-19T19:11:23.632571Z","shell.execute_reply":"2024-12-19T19:11:23.697736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Đăng nhập vào Huggingface\n# có thể không cần thiết phải đăng nhập (?) chỉ cần truyền token vào khi gọi hàm model.push_to_hub() là được\nlogin(token = 'token của người dùng') # phải cung cấp 1 cái token của HF ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:23.700196Z","iopub.execute_input":"2024-12-19T19:11:23.700624Z","iopub.status.idle":"2024-12-19T19:11:23.879668Z","shell.execute_reply.started":"2024-12-19T19:11:23.700575Z","shell.execute_reply":"2024-12-19T19:11:23.878838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **CONFIG**","metadata":{}},{"cell_type":"code","source":"# FacebookAI/roberta-base; FacebookAI/roberta-large\n# cardiffnlp/twitter-roberta-base; cardiffnlp/twitter-roberta-large-2022-154m\n# Twitter/twhin-bert-base; Twitter/twhin-bert-large\n''' đặt tên repo trên huggingface: \nprj-web-mining_{tên model}_{full-train hoặc sample-train}\n'''\n\nmodel_id = \"cardiffnlp/twitter-roberta-large-2022-154m\"  # tên huggingface của pretrained model, kéo về để đi finetune \nsampling_ratio = 1 # 0.0001 có sample tập train để thành tập train bé hơn không? # Note: để = 1 nếu không sample\nnum_epoch = 1\n\nif sampling_ratio == 1:\n    repository_id = f\"shao2011/prj-web-mining_{model_id.split('/')[1]}_full-train\" # tên huggingface để up checkpoint của model lên sau khi finetune xong\nelse:\n    repository_id = f\"shao2011/prj-web-mining_{model_id.split('/')[1]}_sample-train\" # tên huggingface để up checkpoint của model lên sau khi finetune xong\n\n# Các path của các file dataset\ntrain_csv = '/kaggle/input/data-project-web-mining-2024-1/train/train.csv'\nval_text_txt = '/kaggle/input/data-project-web-mining-2024-1/val/val_text.txt'\nval_label_txt = '/kaggle/input/data-project-web-mining-2024-1/val/val_labels.txt'\ntest_text_txt = '/kaggle/input/data-project-web-mining-2024-1/test/test_text.txt'\ntest_label_txt = '/kaggle/input/data-project-web-mining-2024-1/test/test_labels.txt'\n\n# file mapping (id, emoji, label)\nmapping_txt = '/kaggle/input/data-project-web-mining-2024-1/mapping.txt'\n\nprint(model_id)\nprint(repository_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:23.881324Z","iopub.execute_input":"2024-12-19T19:11:23.881590Z","iopub.status.idle":"2024-12-19T19:11:23.887154Z","shell.execute_reply.started":"2024-12-19T19:11:23.881564Z","shell.execute_reply":"2024-12-19T19:11:23.886215Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Load dataset (chuẩn bị dataset)**  \ndataset phải là của class datasets.Dataset (chứ không phải Dataset của pytorch nhé)","metadata":{}},{"cell_type":"code","source":"with open(mapping_txt, 'r') as f:\n    lines = f.read().splitlines()\n    lines = [line.split('\\t') for line in lines]\n    id2label = {int(line[0]): line[2] for line in lines}\n    label2emoji = {line[2]: line[1] for line in lines}\n\n# Hàm tính phân phối của các class trong 1 tập train/val/test -> để kiểm tra xem tập train có mất cân bằng dữ liệu không\ndef class_distributtion(dataset: Dataset, id2label: dict = id2label):\n    count = dict()\n    for i in range(len(dataset)):\n        label = id2label[dataset[i]['label']] #note: dataset[i]['label'] là cái id, là số (còn label là string)\n        if label not in count:\n            count[label] = 0\n        count[label] += 1\n\n    total = len(dataset)\n    for label in count:\n        count[label] = round(count[label]/total*100,2)\n        print(f\"{label}: {count[label]} %\")\n        \n    return count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:23.888493Z","iopub.execute_input":"2024-12-19T19:11:23.888874Z","iopub.status.idle":"2024-12-19T19:11:23.907205Z","shell.execute_reply.started":"2024-12-19T19:11:23.888820Z","shell.execute_reply":"2024-12-19T19:11:23.906328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tạo dataset của tập train\ndf = pd.read_csv(train_csv)\ntrain_dataset = Dataset.from_dict({\n    'text': df['sentence'].to_list(),\n    'label': df['label'].to_list()\n})\nprint(train_dataset)\nprint(train_dataset[0])\nprint(train_dataset[1])\nprint(class_distributtion(train_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:23.908103Z","iopub.execute_input":"2024-12-19T19:11:23.908365Z","iopub.status.idle":"2024-12-19T19:11:42.384588Z","shell.execute_reply.started":"2024-12-19T19:11:23.908318Z","shell.execute_reply":"2024-12-19T19:11:42.383718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tạo dataset của tập val\nwith open(val_text_txt, 'r') as f:\n    val_text = f.read().splitlines()\nwith open(val_label_txt, 'r') as f:\n    val_label = [int(i) for i in f.read().splitlines()]\n    \nval_dataset = Dataset.from_dict({\n    'text': val_text,\n    'label': val_label\n})\nprint(val_dataset)\nprint(val_dataset[0])\nprint(val_dataset[1])\nprint(class_distributtion(val_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:42.385817Z","iopub.execute_input":"2024-12-19T19:11:42.386180Z","iopub.status.idle":"2024-12-19T19:11:42.622016Z","shell.execute_reply.started":"2024-12-19T19:11:42.386139Z","shell.execute_reply":"2024-12-19T19:11:42.621206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tạo dataset của tập test\nwith open(test_text_txt, 'r') as f:\n    test_text = f.read().splitlines()\nwith open(test_label_txt, 'r') as f:\n    test_label = [int(i) for i in f.read().splitlines()]\n    \ntest_dataset = Dataset.from_dict({\n    'text': test_text,\n    'label': test_label\n})\nprint(test_dataset)\nprint(test_dataset[0])\nprint(test_dataset[1])\nprint(class_distributtion(test_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:42.623237Z","iopub.execute_input":"2024-12-19T19:11:42.623999Z","iopub.status.idle":"2024-12-19T19:11:44.675261Z","shell.execute_reply.started":"2024-12-19T19:11:42.623958Z","shell.execute_reply":"2024-12-19T19:11:44.674407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# giải phóng bộ nhớ\ndf = None\nval_text = None\nval_label = None\ntest_text = None\ntest_label = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:44.676376Z","iopub.execute_input":"2024-12-19T19:11:44.676658Z","iopub.status.idle":"2024-12-19T19:11:44.709301Z","shell.execute_reply.started":"2024-12-19T19:11:44.676632Z","shell.execute_reply":"2024-12-19T19:11:44.708414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def preprocess(text):\n#     new_text = []\n#     state1 = False\n#     state2 = False\n#     for t in text.split(\" \"):\n#         if t.startswith('@') and len(t) > 1: \n#             state1 = True\n#         if t.startswith('http'):\n#             state2 = True\n        \n#         t = '@user' if t.startswith('@') and len(t) > 1 else t\n#         t = 'http' if t.startswith('http') else t\n#         new_text.append(t)\n        \n#     if state1 or state2:\n#         print(state1, state2)\n#         print('Câu gốc:', text)    \n#         print('Câu mới:', \" \".join(new_text))\n              \n#     return \" \".join(new_text)\n\n# for i in range(len(val_dataset)):\n#     sen = test_dataset[i]['text']\n#     new_sen = preprocess(sen)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:44.712142Z","iopub.execute_input":"2024-12-19T19:11:44.712470Z","iopub.status.idle":"2024-12-19T19:11:44.740798Z","shell.execute_reply.started":"2024-12-19T19:11:44.712444Z","shell.execute_reply":"2024-12-19T19:11:44.739991Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Sample tập train nhỏ hơn**","metadata":{}},{"cell_type":"code","source":"# sample tập train nhỏ hơn\ntrain_dataset = train_dataset.shuffle().select(range(int(sampling_ratio * len(train_dataset))))\nprint(train_dataset)\nprint(class_distributtion(train_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:44.741826Z","iopub.execute_input":"2024-12-19T19:11:44.742131Z","iopub.status.idle":"2024-12-19T19:11:44.877814Z","shell.execute_reply.started":"2024-12-19T19:11:44.742100Z","shell.execute_reply":"2024-12-19T19:11:44.876982Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Preprocessing**","metadata":{}},{"cell_type":"markdown","source":"### Tokenize các câu (sentence) bằng Tokenizer của model pretrained","metadata":{}},{"cell_type":"code","source":"# Load lại tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_id) # để sẵn: model = AutoModelForMaskedLM.from_pretrained(\"FacebookAI/roberta-base\")\n\n# Hàm tokenize: hàm này sử dụng cái Tokenizer của Roberata để tokenize cho các câu (biến mỗi một câu thành các token)\n# Nó sẽ padding nếu câu ngắn hơn 256 và nó sẽ truncate (cắt xén) nếu câu dài hơn 256; 256 là cái max_length truyền vào.\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=256)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:44.878941Z","iopub.execute_input":"2024-12-19T19:11:44.879310Z","iopub.status.idle":"2024-12-19T19:11:47.233070Z","shell.execute_reply.started":"2024-12-19T19:11:44.879254Z","shell.execute_reply":"2024-12-19T19:11:47.232104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = train_dataset.map(tokenize, batched=True, batch_size= len(train_dataset))\nval_dataset = val_dataset.map(tokenize, batched=True, batch_size= len(val_dataset))\ntest_dataset = test_dataset.map(tokenize, batched=True, batch_size= len(test_dataset))\n\n# print(train_dataset)\n# print(val_dataset)\n# print(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:47.234164Z","iopub.execute_input":"2024-12-19T19:11:47.234511Z","iopub.status.idle":"2024-12-19T19:11:52.405930Z","shell.execute_reply.started":"2024-12-19T19:11:47.234475Z","shell.execute_reply":"2024-12-19T19:11:52.405201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_dataset)\nprint(val_dataset)\nprint(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:52.406840Z","iopub.execute_input":"2024-12-19T19:11:52.407065Z","iopub.status.idle":"2024-12-19T19:11:52.412388Z","shell.execute_reply.started":"2024-12-19T19:11:52.407042Z","shell.execute_reply":"2024-12-19T19:11:52.411522Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Set dataset format","metadata":{}},{"cell_type":"code","source":"# Set dataset format\ntrain_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nval_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\ntest_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n\ntrain_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:52.413841Z","iopub.execute_input":"2024-12-19T19:11:52.414086Z","iopub.status.idle":"2024-12-19T19:11:52.537635Z","shell.execute_reply.started":"2024-12-19T19:11:52.414060Z","shell.execute_reply":"2024-12-19T19:11:52.536847Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Xác định Cấu Hình (config) của model**\nMỗi model đều có 1 cấu hình (configuration - viết tắt là config), cấu hình xác định nhiều khía cạnh của model.  \nThử print cái cấu hình (config) sau đây thì sẽ thấy các khía cạnh nào.  \nCái cấu hình này chính là cấu hình của model được tạo ra (ở dòng `RobertaForSequenceClassification.from_pretrained(...)` )","metadata":{}},{"cell_type":"code","source":"# Tạo object Config, nó biểu diễn cấu hình của model\nconfig = AutoConfig.from_pretrained(model_id) # lấy cấu hình của model pretrained luôn (vào cái pretrained model trên HF: https://huggingface.co/FacebookAI/roberta-base/tree/main, rồi vào tab files and versions, rồi vào file config.json sẽ thấy)\n\n# thêm cái id2label để phục vụ cho việc cấu hình các khía cạnh liên quan đến số class phân loại. \n# (nếu ko có, thì mặc định sẽ là binary classification)\nconfig.update({'id2label': id2label}) # Phải đặt tên là id2label thì mới nhận diện được đây là các class output ra. \nprint(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:52.538618Z","iopub.execute_input":"2024-12-19T19:11:52.538943Z","iopub.status.idle":"2024-12-19T19:11:52.715422Z","shell.execute_reply.started":"2024-12-19T19:11:52.538916Z","shell.execute_reply":"2024-12-19T19:11:52.714344Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Tạo model và Load model**\n- Cái cấu hình (config) được truyền vào để cấu hình lại model được tạo ra (ví dụ: `architecture` được dùng là gì, `hàm activate` là relu hay gelu, `id2label` như nào để còn tạo số nơ-ron của layer cuối trong bộ classifier, ...)\n- Còn cái string \"FacebookAI/roberta-base\" chỉ là được dùng để xác định chỗ load trọng số pretrained thôi. (các trọng số pretrained sẽ được lấy giá trị từ cái checkpoint/repo tên là \"FacebookAI/roberta-base\").  \n","metadata":{}},{"cell_type":"code","source":"if 'bert' in set(model_id.split('/')[1].split(\"-\")):\n    model = BertForSequenceClassification.from_pretrained(model_id, config = config)\nelse:\n    model = RobertaForSequenceClassification.from_pretrained(model_id, config = config)\nprint('bert' in set(model_id.split('/')[1].split(\"-\")))\n\nprint(model) # để ý: trong cái lớp (layer) out_proj xem cái out_features có = số class (= 20) không ?","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:11:52.716745Z","iopub.execute_input":"2024-12-19T19:11:52.717120Z","iopub.status.idle":"2024-12-19T19:12:00.716149Z","shell.execute_reply.started":"2024-12-19T19:11:52.717092Z","shell.execute_reply":"2024-12-19T19:12:00.715320Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Train model**","metadata":{}},{"cell_type":"markdown","source":"### Tạo Training Arguments và Trainer để train và cả evaluate model luôn\nlink doc của class Trainer: https://huggingface.co/docs/transformers/main_classes/trainer","metadata":{}},{"cell_type":"code","source":"def macro_average_f1_score(evalPrediction: EvalPrediction):\n    pred = np.argmax(evalPrediction.predictions, axis = 1)\n    print(len(pred))\n    print(pred)\n    gold = list(evalPrediction.label_ids)\n    \n    report = classification_report(gold, pred, output_dict=True)\n    f1_score = report['macro avg']['f1-score'] \n    acc_score = report['accuracy']\n    return {'macro avg F1': f1_score, 'accuracy': acc_score}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:12:00.717184Z","iopub.execute_input":"2024-12-19T19:12:00.717468Z","iopub.status.idle":"2024-12-19T19:12:00.721783Z","shell.execute_reply.started":"2024-12-19T19:12:00.717442Z","shell.execute_reply":"2024-12-19T19:12:00.720978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir=repository_id,\n    \n    num_train_epochs= num_epoch,\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    warmup_steps=500,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    \n    evaluation_strategy=\"epoch\",\n    logging_dir=f\"{repository_id}/logs\",\n    logging_strategy=\"steps\",\n    logging_steps=10,\n    save_strategy=\"epoch\",\n\n    load_best_model_at_end=True,\n    metric_for_best_model = 'macro avg F1',\n    save_total_limit=1,\n    report_to=\"tensorboard\",\n\n    push_to_hub=True,\n    hub_strategy=\"every_save\",\n    hub_model_id=repository_id,\n    hub_token=HfFolder.get_token(),\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics = macro_average_f1_score\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:12:00.722868Z","iopub.execute_input":"2024-12-19T19:12:00.723190Z","iopub.status.idle":"2024-12-19T19:12:01.600419Z","shell.execute_reply.started":"2024-12-19T19:12:00.723154Z","shell.execute_reply":"2024-12-19T19:12:01.599505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:12:01.601546Z","iopub.execute_input":"2024-12-19T19:12:01.601932Z","iopub.status.idle":"2024-12-19T19:13:51.416760Z","shell.execute_reply.started":"2024-12-19T19:12:01.601898Z","shell.execute_reply":"2024-12-19T19:13:51.415351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_result = trainer.evaluate(eval_dataset=test_dataset)\nprint(\"Kết quả eval trên test set\")\nfor k in test_result:\n    print(f\"{k}: {test_result[k]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:13:56.283945Z","iopub.execute_input":"2024-12-19T19:13:56.285031Z","iopub.status.idle":"2024-12-19T19:14:35.302221Z","shell.execute_reply.started":"2024-12-19T19:13:56.284980Z","shell.execute_reply":"2024-12-19T19:14:35.301411Z"}},"outputs":[],"execution_count":null}]}
